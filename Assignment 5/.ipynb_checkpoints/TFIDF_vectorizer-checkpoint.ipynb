{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVCBaTi8bIdh"
   },
   "source": [
    "# Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "1ikY0V838vr0"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "uDLC_cGA8vr1"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from pandas import DataFrame\n",
    "\n",
    "def document_matrix(list, vectorizer):\n",
    "    doc_matrix = vectorizer.fit_transform(list)\n",
    "    return DataFrame(doc_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8aWIQ9P8vr1",
    "outputId": "5b0c4db1-6293-4329-c9de-abf58843acd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  document  first  is  one  second  the  third  this\n",
      "0    0         1      1   1    0       0    1      0     1\n",
      "1    0         2      0   1    0       1    1      0     1\n",
      "2    1         0      0   1    1       0    1      1     1\n",
      "3    0         1      1   1    0       0    1      0     1\n"
     ]
    }
   ],
   "source": [
    "## Prints the number of words appear in a particular document\n",
    "count_output = document_matrix(corpus, count_vectorizer)\n",
    "print(count_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ud_TFPN8vr4",
    "outputId": "18d6b2a7-fd72-418b-be1c-9d9bd70bd906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and  document     first        is       one    second       the  \\\n",
      "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
      "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
      "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "\n",
      "      third      this  \n",
      "0  0.000000  0.384085  \n",
      "1  0.000000  0.281089  \n",
      "2  0.511849  0.267104  \n",
      "3  0.000000  0.384085  \n"
     ]
    }
   ],
   "source": [
    "## Prints the tfidf value of words in a particular document\n",
    "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
    "print(tfidf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0-rLoKr8vr4",
    "outputId": "68d76a4a-a49b-44c0-ce07-75c30c8343e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6iIwkdNa8vr4",
    "outputId": "ac57a1e5-048f-468b-a748-8e4c3f87b594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFYZ_JQ78vr4",
    "outputId": "434db531-c2e5-42f3-9bed-dd04bae1c81b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huRCIDNX8vr5",
    "outputId": "dfc4d872-cd28-4d3a-c3ab-55c1d843a67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (1, 6)\t0.281088674033753\n",
      "  (1, 5)\t0.5386476208856763\n",
      "  (1, 3)\t0.281088674033753\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (3, 8)\t0.38408524091481483\n",
      "  (3, 6)\t0.38408524091481483\n",
      "  (3, 3)\t0.38408524091481483\n",
      "  (3, 2)\t0.5802858236844359\n",
      "  (3, 1)\t0.46979138557992045\n"
     ]
    }
   ],
   "source": [
    "skl_output = tfidf_vectorizer.transform(corpus)\n",
    "print(skl_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTI7scDM8vr5",
    "outputId": "b4c5efeb-22ba-45ee-988d-724b3940733f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n"
     ]
    }
   ],
   "source": [
    "print(skl_output[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZu7jrYl8vr5",
    "outputId": "65888967-d85c-46fe-f92d-05bb9ac7ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "print(skl_output[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "DAoUzxH58vr5"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "TYEJFWzH8vr5"
   },
   "outputs": [],
   "source": [
    "def get_unique_words(data):\n",
    "  unique_words = set()\n",
    "\n",
    "  if isinstance(data, (list,)):\n",
    "    for row in data:\n",
    "      for word in row.split(' '):\n",
    "        if(len(word) < 2):\n",
    "          continue\n",
    "        unique_words.add(word)\n",
    "    \n",
    "    unique_words = sorted(list(unique_words))\n",
    "    return unique_words\n",
    "  else:\n",
    "    print('pass list of sentences')\n",
    "\n",
    "\n",
    "def get_vocab(unique_words):\n",
    "  vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "  return vocab\n",
    "\n",
    "\n",
    "def transform(corpus, vocab):\n",
    "  rows = []\n",
    "  columns = []\n",
    "  values = []\n",
    "\n",
    "  if isinstance(corpus, (list,)):\n",
    "    for index, row in enumerate(tqdm(corpus)):\n",
    "      word_freq = dict(Counter(row.split()))\n",
    "      for word, freq in word_freq.items():\n",
    "        if len(word) < 2:\n",
    "          continue\n",
    "        \n",
    "        col_index = vocab.get(word, -1)\n",
    "        if col_index != -1:\n",
    "          rows.append(index)\n",
    "          columns.append(col_index)\n",
    "          values.append(freq)\n",
    "    return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(vocab)))\n",
    "  else:\n",
    "    print('pass a list of strings')\n",
    "\n",
    "\n",
    "def get_freq(corpus, unique_words):\n",
    "  flattened = [val for sublist in corpus for val in sublist.split(' ')]\n",
    "  freq = {}\n",
    "  for word in unique_words:\n",
    "    freq[word] = flattened.count(word)\n",
    "  return freq\n",
    "\n",
    "\n",
    "def find_in_str(str, word):\n",
    "  str_list = str.split(' ')\n",
    "  for i in range(len(str_list)):\n",
    "    if(word == str_list[i]):\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def compute_tfidf(corpus, unique_words, transform_output):\n",
    "  rows = []\n",
    "  columns = []\n",
    "  tf = []\n",
    "  idf = []\n",
    "  values = []\n",
    "\n",
    "  for i in range(len(corpus)):\n",
    "    count = 0\n",
    "    \n",
    "    for j in range(len(unique_words)):\n",
    "        temp = transform_output[i][j]\n",
    "        if(temp > 0):\n",
    "           count += temp\n",
    "    for j in range(len(unique_words)):\n",
    "        temp = transform_output[i][j]\n",
    "        if(temp > 0):\n",
    "            tf_value = temp / count\n",
    "            idf_value = math.log( (len(corpus) + 1)/( float(get_idf(corpus, unique_words[j] ) + 1)) ) + 1\n",
    "            rows.append(i)\n",
    "            columns.append(j)\n",
    "            values.append(tf_value * idf_value)\n",
    "  return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(unique_words)))\n",
    "\n",
    "\n",
    "def get_idf(corpus, word):\n",
    "  count = 0\n",
    "  for j in range(len(corpus)):\n",
    "    if(find_in_str(corpus[j], word)):\n",
    "      count += 1\n",
    "  return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9MpEh1u_i-G",
    "outputId": "bb0a4ced-43bf-49ff-daaa-35ee20810f79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n",
      "  (1, 1)\t0.6876235979836937\n",
      "  (1, 3)\t0.2810886740337529\n",
      "  (1, 5)\t0.5386476208856762\n",
      "  (1, 6)\t0.2810886740337529\n",
      "  (1, 8)\t0.2810886740337529\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (3, 1)\t0.4697913855799205\n",
      "  (3, 2)\t0.580285823684436\n",
      "  (3, 3)\t0.3840852409148149\n",
      "  (3, 6)\t0.3840852409148149\n",
      "  (3, 8)\t0.3840852409148149 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unique_words = get_unique_words(corpus)\n",
    "vocab = get_vocab(unique_words)\n",
    "frequency_of_words = get_freq(corpus, unique_words)\n",
    "sparse_matrix = transform(corpus, vocab)\n",
    "transform_output = transform(corpus, vocab).toarray()\n",
    "print(\"\\n\")\n",
    "# print(unique_words)\n",
    "# print(vocab)\n",
    "# print(frequency_of_words)\n",
    "# print(sparse_matrix)\n",
    "# print(transform_output)\n",
    "tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
    "print(normalize(tf_idf, norm = 'l2'), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bhn25nFnclz6",
    "outputId": "c6602ce7-53cc-42aa-bbd4-59ef9afb8ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and  document     first        is       one    second       the  \\\n",
      "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
      "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
      "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
      "\n",
      "      third      this  \n",
      "0  0.000000  0.384085  \n",
      "1  0.000000  0.281089  \n",
      "2  0.511849  0.267104  \n",
      "3  0.000000  0.384085  \n"
     ]
    }
   ],
   "source": [
    "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
    "print(tfidf_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfpBFMTIFW1K"
   },
   "source": [
    "## Observation:\n",
    "*   The list of unique words and their frequencies in entire document is same as the one calculated using TfidfVectorizer\n",
    "*   The transform matrix that contains unique words is same as get_feature_names of scikit learn TfidfVectorizer\n",
    "*   The transform output matrix is same as count_output that we calculated previously using scikit learn CountVectorizer.\n",
    "*   Shape of the transform matrix matches with the one calculated using TfidfVectorizer transform method.\n",
    "*   IDF values of all unique words from the entire document matches the values that were counted using scikit learn TfidfVectorizer.\n",
    "*   IDF_ values calculated by multiplying TF*IDF values individually, matches with the values calculated using TfidfVectorizer._idf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI9PsvSccOX5"
   },
   "source": [
    "# Task-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "-sUDiXcFcQcb",
    "outputId": "0421df9d-bbd0-4f93-bedf-7f70903b2af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "  corpus = pickle.load(f)\n",
    "\n",
    "print(\"Number of documents in corpus = \",len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_BFBJ6yvdBVI"
   },
   "outputs": [],
   "source": [
    "def compute_topidf(corpus, unique_words):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    top50_idf = []\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        count = 0\n",
    "        \n",
    "        for j in range(len(unique_words)):\n",
    "#             temp = transform_output[i][j]\n",
    "#             if(temp > 0):\n",
    "                idf_value = math.log( (len(corpus) + 1)/( float(get_idf(corpus, unique_words[j] ) + 1)) ) + 1\n",
    "                rows.append(i)\n",
    "                columns.append(j)\n",
    "                values.append(idf_value)\n",
    "    top50_idf = sorted(values)\n",
    "    return top50_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     aailiyah  abandoned  ability  abroad  absolutely  abstruse  abysmal  \\\n",
      "0         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "1         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "2         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "3         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "4         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "5         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "6         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "7         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "8         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "9         0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "10        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "11        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "12        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "13        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "14        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "15        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "16        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "17        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "18        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "19        0.0        0.0      0.0     0.0    0.032711       0.0      0.0   \n",
      "20        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "21        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "22        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "23        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "24        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "25        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "26        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "27        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "28        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "29        0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "..        ...        ...      ...     ...         ...       ...      ...   \n",
      "716       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "717       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "718       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "719       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "720       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "721       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "722       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "723       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "724       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "725       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "726       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "727       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "728       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "729       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "730       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "731       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "732       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "733       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "734       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "735       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "736       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "737       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "738       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "739       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "740       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "741       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "742       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "743       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "744       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "745       0.0        0.0      0.0     0.0    0.000000       0.0      0.0   \n",
      "\n",
      "     academy  accents  accessible   ...          yes  yet     young  younger  \\\n",
      "0        0.0      0.0         0.0   ...     0.000000  0.0  0.357811      0.0   \n",
      "1        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "2        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "3        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "4        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "5        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "6        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "7        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "8        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "9        0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "10       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "11       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "12       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "13       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "14       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "15       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "16       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "17       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "18       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "19       0.0      0.0         0.0   ...     0.038352  0.0  0.000000      0.0   \n",
      "20       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "21       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "22       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "23       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "24       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "25       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "26       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "27       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "28       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "29       0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "..       ...      ...         ...   ...          ...  ...       ...      ...   \n",
      "716      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "717      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "718      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "719      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "720      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "721      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "722      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "723      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "724      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "725      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "726      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "727      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "728      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "729      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "730      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "731      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "732      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "733      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "734      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "735      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "736      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "737      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "738      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "739      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "740      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "741      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "742      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "743      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "744      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "745      0.0      0.0         0.0   ...     0.000000  0.0  0.000000      0.0   \n",
      "\n",
      "     youthful  youtube  yun  zillion  zombie  zombiez  \n",
      "0    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "1    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "2    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "3    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "4    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "5    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "6    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "7    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "8    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "9    0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "10   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "11   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "12   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "13   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "14   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "15   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "16   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "17   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "18   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "19   0.042619      0.0  0.0      0.0     0.0      0.0  \n",
      "20   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "21   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "22   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "23   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "24   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "25   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "26   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "27   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "28   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "29   0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "..        ...      ...  ...      ...     ...      ...  \n",
      "716  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "717  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "718  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "719  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "720  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "721  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "722  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "723  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "724  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "725  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "726  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "727  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "728  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "729  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "730  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "731  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "732  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "733  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "734  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "735  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "736  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "737  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "738  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "739  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "740  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "741  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "742  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "743  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "744  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "745  0.000000      0.0  0.0      0.0     0.0      0.0  \n",
      "\n",
      "[746 rows x 2886 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
    "print(tfidf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = get_unique_words(corpus)\n",
    "vocab = get_vocab(unique_words)\n",
    "# frequency_of_words = get_freq(corpus, unique_words)\n",
    "# sparse_matrix = transform(corpus, vocab)\n",
    "# transform_output = transform(corpus, vocab).toarray()\n",
    "top50 = compute_topidf(corpus, unique_words)\n",
    "print(\"\\n\")\n",
    "print(top50)\n",
    "# print(frequency_of_words)\n",
    "# print(sparse_matrix)\n",
    "# print(transform_output)\n",
    "# tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
    "# print(normalize(tf_idf, norm = 'l2'), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TFIDF vectorizer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
