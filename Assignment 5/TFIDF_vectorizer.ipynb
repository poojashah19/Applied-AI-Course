{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF_vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojashah19/Data-Science/blob/main/Assignment%205/TFIDF_vectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVCBaTi8bIdh"
      },
      "source": [
        "# Task-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ikY0V838vr0"
      },
      "source": [
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLC_cGA8vr1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from pandas import DataFrame\n",
        "\n",
        "def document_matrix(list, vectorizer):\n",
        "    doc_matrix = vectorizer.fit_transform(list)\n",
        "    return DataFrame(doc_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8aWIQ9P8vr1",
        "outputId": "3acab896-7560-47f1-f500-266ebb11423e"
      },
      "source": [
        "## Prints the number of words appear in a particular document\n",
        "count_output = document_matrix(corpus, count_vectorizer)\n",
        "print(count_output)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   and  document  first  is  one  second  the  third  this\n",
            "0    0         1      1   1    0       0    1      0     1\n",
            "1    0         2      0   1    0       1    1      0     1\n",
            "2    1         0      0   1    1       0    1      1     1\n",
            "3    0         1      1   1    0       0    1      0     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ud_TFPN8vr4",
        "outputId": "56806ea3-685f-4cd6-bed2-7b7bb773b552"
      },
      "source": [
        "## Prints the tfidf value of words in a particular document\n",
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first  ...       the     third      this\n",
            "0  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "1  0.000000  0.687624  0.000000  ...  0.281089  0.000000  0.281089\n",
            "2  0.511849  0.000000  0.000000  ...  0.267104  0.511849  0.267104\n",
            "3  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "\n",
            "[4 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-rLoKr8vr4",
        "outputId": "fb8ea340-b270-4217-95f0-cab9f3411984"
      },
      "source": [
        "print(tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iIwkdNa8vr4",
        "outputId": "9d2ae999-580f-4985-fa37-eebcefcfbae0"
      },
      "source": [
        "print(tfidf_vectorizer.idf_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFYZ_JQ78vr4",
        "outputId": "481c183a-994b-4b00-8589-71452150efc4"
      },
      "source": [
        "tfidf_output.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRCIDNX8vr5",
        "outputId": "6b89b90b-487c-477f-c0fd-5eedccee6030"
      },
      "source": [
        "skl_output = tfidf_vectorizer.transform(corpus)\n",
        "print(skl_output)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (3, 8)\t0.38408524091481483\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTI7scDM8vr5",
        "outputId": "e1e3c652-3761-422f-e232-5bba69b63f13"
      },
      "source": [
        "print(skl_output[3])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZu7jrYl8vr5",
        "outputId": "401fdcc9-ffdd-410c-8146-b3257d8ad4ba"
      },
      "source": [
        "print(skl_output[0].toarray())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAoUzxH58vr5"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYEJFWzH8vr5"
      },
      "source": [
        "def get_unique_words(data):\n",
        "  unique_words = set()\n",
        "\n",
        "  if isinstance(data, (list,)):\n",
        "    for row in data:\n",
        "      for word in row.split(' '):\n",
        "        if(len(word) < 2):\n",
        "          continue\n",
        "        unique_words.add(word)\n",
        "    \n",
        "    unique_words = sorted(list(unique_words))\n",
        "    return unique_words\n",
        "  else:\n",
        "    print('pass list of sentences')\n",
        "\n",
        "\n",
        "def get_vocab(unique_words):\n",
        "  vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def transform(corpus, vocab):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  values = []\n",
        "\n",
        "  if isinstance(corpus, (list,)):\n",
        "    for index, row in enumerate(tqdm(corpus)):\n",
        "      word_freq = dict(Counter(row.split()))\n",
        "      for word, freq in word_freq.items():\n",
        "        if len(word) < 2:\n",
        "          continue\n",
        "        \n",
        "        col_index = vocab.get(word, -1)\n",
        "        if col_index != -1:\n",
        "          rows.append(index)\n",
        "          columns.append(col_index)\n",
        "          values.append(freq)\n",
        "    return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(vocab)))\n",
        "  else:\n",
        "    print('pass a list of strings')\n",
        "\n",
        "\n",
        "def get_freq(corpus, unique_words):\n",
        "  flattened = [val for sublist in corpus for val in sublist.split(' ')]\n",
        "  freq = {}\n",
        "  for word in unique_words:\n",
        "    freq[word] = flattened.count(word)\n",
        "  return freq\n",
        "\n",
        "\n",
        "def find_in_str(str, word):\n",
        "  str_list = str.split(' ')\n",
        "  for i in range(len(str_list)):\n",
        "    if(word == str_list[i]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def compute_tfidf(corpus, unique_words, transform_output):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  tf = []\n",
        "  idf = []\n",
        "  values = []\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    count = 0\n",
        "    \n",
        "    for j in range(len(unique_words)):\n",
        "        temp = transform_output[i][j]\n",
        "        if(temp > 0):\n",
        "           count += temp\n",
        "    for j in range(len(unique_words)):\n",
        "        temp = transform_output[i][j]\n",
        "        if(temp > 0):\n",
        "            tf_value = temp / count\n",
        "            idf_value = math.log( (len(corpus) + 1)/( float(get_idf(corpus, unique_words[j] ) + 1)) ) + 1\n",
        "            rows.append(i)\n",
        "            columns.append(j)\n",
        "            values.append(tf_value * idf_value)\n",
        "  return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(unique_words)))\n",
        "\n",
        "\n",
        "def get_idf(corpus, word):\n",
        "  count = 0\n",
        "  for j in range(len(corpus)):\n",
        "    if(find_in_str(corpus[j], word)):\n",
        "      count += 1\n",
        "  return count\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9MpEh1u_i-G",
        "outputId": "680d5fda-6e96-4519-cf48-7a35be097b52"
      },
      "source": [
        "unique_words = get_unique_words(corpus)\n",
        "vocab = get_vocab(unique_words)\n",
        "frequency_of_words = get_freq(corpus, unique_words)\n",
        "sparse_matrix = transform(corpus, vocab)\n",
        "transform_output = transform(corpus, vocab).toarray()\n",
        "print(\"\\n\")\n",
        "# print(unique_words)\n",
        "# print(vocab)\n",
        "# print(frequency_of_words)\n",
        "# print(sparse_matrix)\n",
        "# print(transform_output)\n",
        "tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
        "print(round(normalize(tf_idf, norm = 'l2'), 6))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 7073.03it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 5344.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  (0, 1)\t0.469791\n",
            "  (0, 2)\t0.580286\n",
            "  (0, 3)\t0.384085\n",
            "  (0, 6)\t0.384085\n",
            "  (0, 8)\t0.384085\n",
            "  (1, 1)\t0.687624\n",
            "  (1, 3)\t0.281089\n",
            "  (1, 5)\t0.538648\n",
            "  (1, 6)\t0.281089\n",
            "  (1, 8)\t0.281089\n",
            "  (2, 0)\t0.511849\n",
            "  (2, 3)\t0.267104\n",
            "  (2, 4)\t0.511849\n",
            "  (2, 6)\t0.267104\n",
            "  (2, 7)\t0.511849\n",
            "  (2, 8)\t0.267104\n",
            "  (3, 1)\t0.469791\n",
            "  (3, 2)\t0.580286\n",
            "  (3, 3)\t0.384085\n",
            "  (3, 6)\t0.384085\n",
            "  (3, 8)\t0.384085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhn25nFnclz6",
        "outputId": "b70db249-aded-4b87-b807-9b073adff7aa"
      },
      "source": [
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first  ...       the     third      this\n",
            "0  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "1  0.000000  0.687624  0.000000  ...  0.281089  0.000000  0.281089\n",
            "2  0.511849  0.000000  0.000000  ...  0.267104  0.511849  0.267104\n",
            "3  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "\n",
            "[4 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfpBFMTIFW1K"
      },
      "source": [
        "## Observation:\n",
        "*   The list of unique words and their frequencies in entire document is same as the one calculated using TfidfVectorizer\n",
        "*   The transform matrix that contains unique words is same as get_feature_names of scikit learn TfidfVectorizer\n",
        "*   The transform output matrix is same as count_output that we calculated previously using scikit learn CountVectorizer.\n",
        "*   Shape of the transform matrix matches with the one calculated using TfidfVectorizer transform method.\n",
        "*   IDF values of all unique words from the entire document matches the values that were counted using scikit learn TfidfVectorizer.\n",
        "*   IDF_ values calculated by multiplying TF*IDF values individually, matches with the values calculated using TfidfVectorizer._idf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI9PsvSccOX5"
      },
      "source": [
        "# Task-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sUDiXcFcQcb",
        "outputId": "0f36dab7-bd5f-4e89-a62a-88687e2070a4"
      },
      "source": [
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "  corpus = pickle.load(f)\n",
        "\n",
        "print(\"Number of documents in corpus = \",len(corpus))\n",
        "\n",
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "data = tfidf_output[:5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents in corpus =  746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BFBJ6yvdBVI"
      },
      "source": [
        "def compute_topidf(corpus, unique_words):\n",
        "    vocab = []\n",
        "    idf = {}\n",
        "    idf_50 = {}\n",
        "    \n",
        "    for col in corpus.columns:\n",
        "      idf_value = math.log( (len(corpus) + 1)/( len( corpus[(corpus[col] > 0)] ) + 1 ) ) + 1\n",
        "      idf[col] = idf_value\n",
        "    idf_50 = { k:v for k, v in sorted( idf.items(), key = lambda item: item[1], reverse=True )[:50] }\n",
        "\n",
        "    vocab = {j:i for i,j in enumerate( list( idf_50.keys() ) )}\n",
        "    return idf_50, vocab"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XcfgKqG_w60",
        "outputId": "3144f653-6bda-4297-bd8d-02a27e451afa"
      },
      "source": [
        "unique_words = data.columns\n",
        "idf_50, vocab = compute_topidf(data, unique_words)\n",
        "print(vocab)\n",
        "print(idf_50)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aailiyah': 0, 'abandoned': 1, 'ability': 2, 'abroad': 3, 'absolutely': 4, 'abstruse': 5, 'abysmal': 6, 'academy': 7, 'accents': 8, 'accessible': 9, 'acclaimed': 10, 'accolades': 11, 'accurate': 12, 'accurately': 13, 'accused': 14, 'achievement': 15, 'achille': 16, 'ackerman': 17, 'act': 18, 'acted': 19, 'action': 20, 'actions': 21, 'actor': 22, 'actors': 23, 'actress': 24, 'actresses': 25, 'actually': 26, 'adams': 27, 'adaptation': 28, 'add': 29, 'added': 30, 'addition': 31, 'admins': 32, 'admiration': 33, 'admitted': 34, 'adorable': 35, 'adrift': 36, 'adventure': 37, 'advise': 38, 'aerial': 39, 'aesthetically': 40, 'affected': 41, 'affleck': 42, 'afraid': 43, 'africa': 44, 'afternoon': 45, 'age': 46, 'aged': 47, 'ages': 48, 'ago': 49}\n",
            "{'aailiyah': 2.791759469228055, 'abandoned': 2.791759469228055, 'ability': 2.791759469228055, 'abroad': 2.791759469228055, 'absolutely': 2.791759469228055, 'abstruse': 2.791759469228055, 'abysmal': 2.791759469228055, 'academy': 2.791759469228055, 'accents': 2.791759469228055, 'accessible': 2.791759469228055, 'acclaimed': 2.791759469228055, 'accolades': 2.791759469228055, 'accurate': 2.791759469228055, 'accurately': 2.791759469228055, 'accused': 2.791759469228055, 'achievement': 2.791759469228055, 'achille': 2.791759469228055, 'ackerman': 2.791759469228055, 'act': 2.791759469228055, 'acted': 2.791759469228055, 'action': 2.791759469228055, 'actions': 2.791759469228055, 'actor': 2.791759469228055, 'actors': 2.791759469228055, 'actress': 2.791759469228055, 'actresses': 2.791759469228055, 'actually': 2.791759469228055, 'adams': 2.791759469228055, 'adaptation': 2.791759469228055, 'add': 2.791759469228055, 'added': 2.791759469228055, 'addition': 2.791759469228055, 'admins': 2.791759469228055, 'admiration': 2.791759469228055, 'admitted': 2.791759469228055, 'adorable': 2.791759469228055, 'adrift': 2.791759469228055, 'adventure': 2.791759469228055, 'advise': 2.791759469228055, 'aerial': 2.791759469228055, 'aesthetically': 2.791759469228055, 'affected': 2.791759469228055, 'affleck': 2.791759469228055, 'afraid': 2.791759469228055, 'africa': 2.791759469228055, 'afternoon': 2.791759469228055, 'age': 2.791759469228055, 'aged': 2.791759469228055, 'ages': 2.791759469228055, 'ago': 2.791759469228055}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}