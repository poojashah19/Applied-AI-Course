{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF_vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojashah19/Data-Science/blob/main/Assignment%205/TFIDF_vectorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVCBaTi8bIdh"
      },
      "source": [
        "# Task-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ikY0V838vr0"
      },
      "source": [
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLC_cGA8vr1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from pandas import DataFrame\n",
        "\n",
        "def document_matrix(list, vectorizer):\n",
        "    doc_matrix = vectorizer.fit_transform(list)\n",
        "    return DataFrame(doc_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8aWIQ9P8vr1",
        "outputId": "5b0c4db1-6293-4329-c9de-abf58843acd8"
      },
      "source": [
        "## Prints the number of words appear in a particular document\n",
        "count_output = document_matrix(corpus, count_vectorizer)\n",
        "print(count_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   and  document  first  is  one  second  the  third  this\n",
            "0    0         1      1   1    0       0    1      0     1\n",
            "1    0         2      0   1    0       1    1      0     1\n",
            "2    1         0      0   1    1       0    1      1     1\n",
            "3    0         1      1   1    0       0    1      0     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ud_TFPN8vr4",
        "outputId": "18d6b2a7-fd72-418b-be1c-9d9bd70bd906"
      },
      "source": [
        "## Prints the tfidf value of words in a particular document\n",
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-rLoKr8vr4",
        "outputId": "68d76a4a-a49b-44c0-ce07-75c30c8343e8"
      },
      "source": [
        "print(tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iIwkdNa8vr4",
        "outputId": "ac57a1e5-048f-468b-a748-8e4c3f87b594"
      },
      "source": [
        "print(tfidf_vectorizer.idf_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFYZ_JQ78vr4",
        "outputId": "434db531-c2e5-42f3-9bed-dd04bae1c81b"
      },
      "source": [
        "tfidf_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRCIDNX8vr5",
        "outputId": "dfc4d872-cd28-4d3a-c3ab-55c1d843a67d"
      },
      "source": [
        "skl_output = tfidf_vectorizer.transform(corpus)\n",
        "print(skl_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (3, 8)\t0.38408524091481483\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTI7scDM8vr5",
        "outputId": "b4c5efeb-22ba-45ee-988d-724b3940733f"
      },
      "source": [
        "print(skl_output[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZu7jrYl8vr5",
        "outputId": "65888967-d85c-46fe-f92d-05bb9ac7ffe2"
      },
      "source": [
        "print(skl_output[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAoUzxH58vr5"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYEJFWzH8vr5"
      },
      "source": [
        "def get_unique_words(data):\n",
        "  unique_words = set()\n",
        "\n",
        "  if isinstance(data, (list,)):\n",
        "    for row in data:\n",
        "      for word in row.split(' '):\n",
        "        if(len(word) < 2):\n",
        "          continue\n",
        "        unique_words.add(word)\n",
        "    \n",
        "    unique_words = sorted(list(unique_words))\n",
        "    return unique_words\n",
        "  else:\n",
        "    print('pass list of sentences')\n",
        "\n",
        "\n",
        "def get_vocab(unique_words):\n",
        "  vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def transform(corpus, vocab):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  values = []\n",
        "\n",
        "  if isinstance(corpus, (list,)):\n",
        "    for index, row in enumerate(tqdm(corpus)):\n",
        "      word_freq = dict(Counter(row.split()))\n",
        "      for word, freq in word_freq.items():\n",
        "        if len(word) < 2:\n",
        "          continue\n",
        "        \n",
        "        col_index = vocab.get(word, -1)\n",
        "        if col_index != -1:\n",
        "          rows.append(index)\n",
        "          columns.append(col_index)\n",
        "          values.append(freq)\n",
        "    return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(vocab)))\n",
        "  else:\n",
        "    print('pass a list of strings')\n",
        "\n",
        "\n",
        "def get_freq(corpus, unique_words):\n",
        "  flattened = [val for sublist in corpus for val in sublist.split(' ')]\n",
        "  freq = {}\n",
        "  for word in unique_words:\n",
        "    freq[word] = flattened.count(word)\n",
        "  return freq\n",
        "\n",
        "\n",
        "def find_in_str(str, word):\n",
        "  str_list = str.split(' ')\n",
        "  for i in range(len(str_list)):\n",
        "    if(word == str_list[i]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def compute_tfidf(corpus, unique_words, transform_output):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  tf = []\n",
        "  idf = []\n",
        "  values = []\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    count = 0\n",
        "    \n",
        "    for j in range(len(unique_words)):\n",
        "        temp = transform_output[i][j]\n",
        "        if(temp > 0):\n",
        "           count += temp\n",
        "    for j in range(len(unique_words)):\n",
        "        temp = transform_output[i][j]\n",
        "        if(temp > 0):\n",
        "            tf_value = temp / count\n",
        "            idf_value = math.log( (len(corpus) + 1)/( float(get_idf(corpus, unique_words[j] ) + 1)) ) + 1\n",
        "            rows.append(i)\n",
        "            columns.append(j)\n",
        "            values.append(tf_value * idf_value)\n",
        "  return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(unique_words)))\n",
        "\n",
        "\n",
        "def get_idf(corpus, word):\n",
        "  count = 0\n",
        "  for j in range(len(corpus)):\n",
        "    if(find_in_str(corpus[j], word)):\n",
        "      count += 1\n",
        "  return count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9MpEh1u_i-G",
        "outputId": "bb0a4ced-43bf-49ff-daaa-35ee20810f79"
      },
      "source": [
        "unique_words = get_unique_words(corpus)\n",
        "vocab = get_vocab(unique_words)\n",
        "frequency_of_words = get_freq(corpus, unique_words)\n",
        "sparse_matrix = transform(corpus, vocab)\n",
        "transform_output = transform(corpus, vocab).toarray()\n",
        "print(\"\\n\")\n",
        "# print(unique_words)\n",
        "# print(vocab)\n",
        "# print(frequency_of_words)\n",
        "# print(sparse_matrix)\n",
        "# print(transform_output)\n",
        "tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
        "print(normalize(tf_idf, norm = 'l2'), 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "  (1, 1)\t0.6876235979836937\n",
            "  (1, 3)\t0.2810886740337529\n",
            "  (1, 5)\t0.5386476208856762\n",
            "  (1, 6)\t0.2810886740337529\n",
            "  (1, 8)\t0.2810886740337529\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.4697913855799205\n",
            "  (3, 2)\t0.580285823684436\n",
            "  (3, 3)\t0.3840852409148149\n",
            "  (3, 6)\t0.3840852409148149\n",
            "  (3, 8)\t0.3840852409148149 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhn25nFnclz6",
        "outputId": "c6602ce7-53cc-42aa-bbd4-59ef9afb8ae1"
      },
      "source": [
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first        is       one    second       the  \\\n",
            "0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n",
            "2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n",
            "3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n",
            "\n",
            "      third      this  \n",
            "0  0.000000  0.384085  \n",
            "1  0.000000  0.281089  \n",
            "2  0.511849  0.267104  \n",
            "3  0.000000  0.384085  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfpBFMTIFW1K"
      },
      "source": [
        "## Observation:\n",
        "*   The list of unique words and their frequencies in entire document is same as the one calculated using TfidfVectorizer\n",
        "*   The transform matrix that contains unique words is same as get_feature_names of scikit learn TfidfVectorizer\n",
        "*   The transform output matrix is same as count_output that we calculated previously using scikit learn CountVectorizer.\n",
        "*   Shape of the transform matrix matches with the one calculated using TfidfVectorizer transform method.\n",
        "*   IDF values of all unique words from the entire document matches the values that were counted using scikit learn TfidfVectorizer.\n",
        "*   IDF_ values calculated by multiplying TF*IDF values individually, matches with the values calculated using TfidfVectorizer._idf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI9PsvSccOX5"
      },
      "source": [
        "# Task-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sUDiXcFcQcb",
        "outputId": "490ab362-4f10-4529-ac4c-9ec611aa3cbd"
      },
      "source": [
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "  corpus = pickle.load(f)\n",
        "\n",
        "print(\"Number of documents in corpus = \",len(corpus))\n",
        "\n",
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "data = tfidf_output[-500:]\n",
        "print(data)\n",
        "print( tfidf_output[(tfidf_output.iloc[:, 78] != 0)] ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents in corpus =  746\n",
            "     aailiyah  abandoned  ability  abroad  ...  yun  zillion  zombie  zombiez\n",
            "246       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "247       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "248       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "249       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "250       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "..        ...        ...      ...     ...  ...  ...      ...     ...      ...\n",
            "741       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "742       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "743       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "744       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "745       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "\n",
            "[500 rows x 2886 columns]\n",
            "     aailiyah  abandoned  ability  abroad  ...  yun  zillion  zombie  zombiez\n",
            "225       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "643       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "\n",
            "[2 rows x 2886 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BFBJ6yvdBVI"
      },
      "source": [
        "def compute_topidf(corpus):\n",
        "    vocab = []\n",
        "    idf = {}\n",
        "    top50_idf = {}\n",
        "    \n",
        "    for col in corpus.columns:\n",
        "      idf_value = math.log( (len(corpus) + 1)/( len( corpus[(corpus[col] > 0)] ) + 1 ) ) + 1\n",
        "      idf[col] = idf_value\n",
        "    top50_idf = { k:v for k, v in sorted( idf.items(), key = lambda item: item[1], reverse=True )[:200] }\n",
        "    return top50_idf\n",
        "\n",
        "\n",
        "def compute_tfidf(corpus, top50_vocab):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  tf = []\n",
        "  idf = []\n",
        "  values = []\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    count = 0\n",
        "    \n",
        "    for j in range(len(corpus.columns)):\n",
        "      colname = corpus.columns[j]\n",
        "      if(colname in top50_vocab):\n",
        "        temp = corpus.iloc[i,j]\n",
        "        if(temp > 0):\n",
        "           count += temp\n",
        "    for j in range(len(corpus.columns)):\n",
        "      colname = corpus.columns[j]\n",
        "      if(colname in top50_vocab):\n",
        "        temp = corpus.iloc[i,j]\n",
        "        if(temp != 0):\n",
        "            tf_value = temp / count\n",
        "            idf_value = math.log( (len(corpus) + 1)/( len( corpus[(corpus.iloc[:, j] > 0)] ) + 1 ) ) + 1\n",
        "            rows.append(i)\n",
        "            columns.append(j)\n",
        "            print(tf_value, idf_value)\n",
        "            values.append(tf_value * idf_value)\n",
        "  return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(corpus.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XcfgKqG_w60",
        "outputId": "a24ddce5-42aa-4b4b-c05b-7d4faa22191a"
      },
      "source": [
        "unique_words = data.columns\n",
        "vocab = get_vocab(unique_words)\n",
        "# frequency_of_words = get_freq(corpus, unique_words)\n",
        "# sparse_matrix = transform(corpus, vocab)\n",
        "# transform_output = transform(corpus, vocab).toarray()\n",
        "top50_vocab = compute_topidf(data)\n",
        "print(top50_vocab)\n",
        "\n",
        "tf_idf = compute_tfidf(data, top50_vocab)\n",
        "print(tf_idf)\n",
        "print(normalize(tf_idf, norm = 'l2'))\n",
        "# print(frequency_of_words)\n",
        "# print(sparse_matrix)\n",
        "# print(transform_output)\n",
        "# tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
        "# print(normalize(tf_idf, norm = 'l2'), 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'abroad': 7.2166061010848646, 'abstruse': 7.2166061010848646, 'accurately': 7.2166061010848646, 'actions': 7.2166061010848646, 'admins': 7.2166061010848646, 'admiration': 7.2166061010848646, 'admitted': 7.2166061010848646, 'adrift': 7.2166061010848646, 'adventure': 7.2166061010848646, 'affected': 7.2166061010848646, 'affleck': 7.2166061010848646, 'agreed': 7.2166061010848646, 'aimless': 7.2166061010848646, 'aired': 7.2166061010848646, 'akin': 7.2166061010848646, 'allison': 7.2166061010848646, 'amateurish': 7.2166061010848646, 'amaze': 7.2166061010848646, 'amusing': 7.2166061010848646, 'angel': 7.2166061010848646, 'angelina': 7.2166061010848646, 'angles': 7.2166061010848646, 'angry': 7.2166061010848646, 'animals': 7.2166061010848646, 'anthony': 7.2166061010848646, 'appealing': 7.2166061010848646, 'appears': 7.2166061010848646, 'applause': 7.2166061010848646, 'apt': 7.2166061010848646, 'array': 7.2166061010848646, 'articulated': 7.2166061010848646, 'artiness': 7.2166061010848646, 'artist': 7.2166061010848646, 'artistic': 7.2166061010848646, 'artless': 7.2166061010848646, 'ask': 7.2166061010848646, 'assistant': 7.2166061010848646, 'atrocity': 7.2166061010848646, 'attempting': 7.2166061010848646, 'author': 7.2166061010848646, 'average': 7.2166061010848646, 'awarded': 7.2166061010848646, 'aye': 7.2166061010848646, 'babie': 7.2166061010848646, 'baby': 7.2166061010848646, 'backed': 7.2166061010848646, 'badly': 7.2166061010848646, 'bag': 7.2166061010848646, 'bakery': 7.2166061010848646, 'ballet': 7.2166061010848646, 'balls': 7.2166061010848646, 'barney': 7.2166061010848646, 'barren': 7.2166061010848646, 'bat': 7.2166061010848646, 'bec': 7.2166061010848646, 'bela': 7.2166061010848646, 'believed': 7.2166061010848646, 'bell': 7.2166061010848646, 'bellucci': 7.2166061010848646, 'belmondo': 7.2166061010848646, 'ben': 7.2166061010848646, 'bergen': 7.2166061010848646, 'billy': 7.2166061010848646, 'biographical': 7.2166061010848646, 'bitchy': 7.2166061010848646, 'blatant': 7.2166061010848646, 'blew': 7.2166061010848646, 'blue': 7.2166061010848646, 'boasts': 7.2166061010848646, 'bob': 7.2166061010848646, 'bold': 7.2166061010848646, 'bond': 7.2166061010848646, 'bonus': 7.2166061010848646, 'boogeyman': 7.2166061010848646, 'bop': 7.2166061010848646, 'bordered': 7.2166061010848646, 'boss': 7.2166061010848646, 'box': 7.2166061010848646, 'boyfriend': 7.2166061010848646, 'brevity': 7.2166061010848646, 'brigand': 7.2166061010848646, 'bring': 7.2166061010848646, 'brother': 7.2166061010848646, 'buffet': 7.2166061010848646, 'builders': 7.2166061010848646, 'buildings': 7.2166061010848646, 'bully': 7.2166061010848646, 'bunch': 7.2166061010848646, 'burton': 7.2166061010848646, 'buy': 7.2166061010848646, 'cameo': 7.2166061010848646, 'camerawork': 7.2166061010848646, 'cancan': 7.2166061010848646, 'candace': 7.2166061010848646, 'cannot': 7.2166061010848646, 'cant': 7.2166061010848646, 'car': 7.2166061010848646, 'carrell': 7.2166061010848646, 'carry': 7.2166061010848646, 'cases': 7.2166061010848646, 'casted': 7.2166061010848646, 'caught': 7.2166061010848646, 'celebration': 7.2166061010848646, 'certain': 7.2166061010848646, 'chalkboard': 7.2166061010848646, 'changing': 7.2166061010848646, 'charles': 7.2166061010848646, 'charm': 7.2166061010848646, 'chase': 7.2166061010848646, 'check': 7.2166061010848646, 'cheekbones': 7.2166061010848646, 'chick': 7.2166061010848646, 'chills': 7.2166061010848646, 'chilly': 7.2166061010848646, 'chimp': 7.2166061010848646, 'choice': 7.2166061010848646, 'choices': 7.2166061010848646, 'chosen': 7.2166061010848646, 'christopher': 7.2166061010848646, 'circumstances': 7.2166061010848646, 'cliche': 7.2166061010848646, 'club': 7.2166061010848646, 'co': 7.2166061010848646, 'coal': 7.2166061010848646, 'coaster': 7.2166061010848646, 'colours': 7.2166061010848646, 'columbo': 7.2166061010848646, 'commentary': 7.2166061010848646, 'community': 7.2166061010848646, 'concentrate': 7.2166061010848646, 'conception': 7.2166061010848646, 'conceptually': 7.2166061010848646, 'concert': 7.2166061010848646, 'confirm': 7.2166061010848646, 'confuses': 7.2166061010848646, 'connections': 7.2166061010848646, 'considered': 7.2166061010848646, 'constructed': 7.2166061010848646, 'content': 7.2166061010848646, 'continually': 7.2166061010848646, 'continuation': 7.2166061010848646, 'contributory': 7.2166061010848646, 'controversy': 7.2166061010848646, 'convince': 7.2166061010848646, 'convoluted': 7.2166061010848646, 'core': 7.2166061010848646, 'corn': 7.2166061010848646, 'correct': 7.2166061010848646, 'cost': 7.2166061010848646, 'cotton': 7.2166061010848646, 'couple': 7.2166061010848646, 'cover': 7.2166061010848646, 'crackles': 7.2166061010848646, 'crafted': 7.2166061010848646, 'crash': 7.2166061010848646, 'crayons': 7.2166061010848646, 'crime': 7.2166061010848646, 'crocdodile': 7.2166061010848646, 'crocs': 7.2166061010848646, 'cross': 7.2166061010848646, 'cry': 7.2166061010848646, 'curtain': 7.2166061010848646, 'cute': 7.2166061010848646, 'cutest': 7.2166061010848646, 'cutouts': 7.2166061010848646, 'cutting': 7.2166061010848646, 'damian': 7.2166061010848646, 'dangerous': 7.2166061010848646, 'dealt': 7.2166061010848646, 'debated': 7.2166061010848646, 'debbie': 7.2166061010848646, 'defensemen': 7.2166061010848646, 'defined': 7.2166061010848646, 'depending': 7.2166061010848646, 'depressing': 7.2166061010848646, 'depth': 7.2166061010848646, 'designed': 7.2166061010848646, 'designer': 7.2166061010848646, 'desperately': 7.2166061010848646, 'detailing': 7.2166061010848646, 'develop': 7.2166061010848646, 'developments': 7.2166061010848646, 'dialogs': 7.2166061010848646, 'directors': 7.2166061010848646, 'disaster': 7.2166061010848646, 'disbelief': 7.2166061010848646, 'discovery': 7.2166061010848646, 'disgusting': 7.2166061010848646, 'disparate': 7.2166061010848646, 'distinction': 7.2166061010848646, 'distressed': 7.2166061010848646, 'diving': 7.2166061010848646, 'dodge': 7.2166061010848646, 'dollars': 7.2166061010848646, 'doomed': 7.2166061010848646, 'dozen': 7.2166061010848646, 'drag': 7.2166061010848646, 'drago': 7.2166061010848646, 'dribble': 7.2166061010848646, 'drifting': 7.2166061010848646}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2HJ1MQwaz3c",
        "outputId": "9e33acfe-ec78-4e9c-bc41-bcf7ae60f40b"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=50)\r\n",
        "vectorizer.fit(data)\r\n",
        "new_output = vectorizer.transform(data)\r\n",
        "print(vectorizer.idf_)\r\n",
        "print(vectorizer.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826 8.274826\n",
            " 8.274826 8.274826]\n",
            "{'aailiyah': 0, 'portrayed': 1, 'portraying': 2, 'positive': 3, 'possible': 4, 'possibly': 5, 'post': 6, 'potted': 7, 'power': 8, 'powerful': 9, 'powerhouse': 10, 'practical': 11, 'practically': 12, 'pray': 13, 'precisely': 14, 'predict': 15, 'predictable': 16, 'predictably': 17, 'prejudice': 18, 'prelude': 19, 'premise': 20, 'prepared': 21, 'presence': 22, 'presents': 23, 'preservation': 24, 'president': 25, 'pretentious': 26, 'pretext': 27, 'pretty': 28, 'previous': 29, 'primal': 30, 'primary': 31, 'probably': 32, 'problem': 33, 'problems': 34, 'proceedings': 35, 'process': 36, 'produce': 37, 'produced': 38, 'producer': 39, 'producers': 40, 'product': 41, 'production': 42, 'professionals': 43, 'professor': 44, 'promote': 45, 'pure': 46, 'purity': 47, 'put': 48, 'putting': 49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-J0wCkR_w61",
        "outputId": "9930f431-0c7a-468e-82cf-5b6d1c68ee1f"
      },
      "source": [
        "tfidf_output = document_matrix(data, tfidf_vectorizer)\r\n",
        "print(tfidf_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      aailiyah  abandoned  ability  abroad  ...  yun  zillion  zombie  zombiez\n",
            "0          1.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "1          0.0        1.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "2          0.0        0.0      1.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "3          0.0        0.0      0.0     1.0  ...  0.0      0.0     0.0      0.0\n",
            "4          0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "...        ...        ...      ...     ...  ...  ...      ...     ...      ...\n",
            "2881       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      0.0\n",
            "2882       0.0        0.0      0.0     0.0  ...  1.0      0.0     0.0      0.0\n",
            "2883       0.0        0.0      0.0     0.0  ...  0.0      1.0     0.0      0.0\n",
            "2884       0.0        0.0      0.0     0.0  ...  0.0      0.0     1.0      0.0\n",
            "2885       0.0        0.0      0.0     0.0  ...  0.0      0.0     0.0      1.0\n",
            "\n",
            "[2886 rows x 2886 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP1r6bQWaltj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}