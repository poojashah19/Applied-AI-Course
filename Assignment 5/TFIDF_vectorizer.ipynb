{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "TFIDF vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVCBaTi8bIdh"
      },
      "source": [
        "# Task-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ikY0V838vr0"
      },
      "source": [
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLC_cGA8vr1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from pandas import DataFrame\n",
        "\n",
        "def document_matrix(list, vectorizer):\n",
        "    doc_matrix = vectorizer.fit_transform(list)\n",
        "    return DataFrame(doc_matrix.toarray(), columns = vectorizer.get_feature_names())\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8aWIQ9P8vr1",
        "outputId": "5b0c4db1-6293-4329-c9de-abf58843acd8"
      },
      "source": [
        "## Prints the number of words appear in a particular document\n",
        "count_output = document_matrix(corpus, count_vectorizer)\n",
        "print(count_output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   and  document  first  is  one  second  the  third  this\n",
            "0    0         1      1   1    0       0    1      0     1\n",
            "1    0         2      0   1    0       1    1      0     1\n",
            "2    1         0      0   1    1       0    1      1     1\n",
            "3    0         1      1   1    0       0    1      0     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ud_TFPN8vr4",
        "outputId": "18d6b2a7-fd72-418b-be1c-9d9bd70bd906"
      },
      "source": [
        "## Prints the tfidf value of words in a particular document\n",
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first  ...       the     third      this\n",
            "0  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "1  0.000000  0.687624  0.000000  ...  0.281089  0.000000  0.281089\n",
            "2  0.511849  0.000000  0.000000  ...  0.267104  0.511849  0.267104\n",
            "3  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "\n",
            "[4 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-rLoKr8vr4",
        "outputId": "68d76a4a-a49b-44c0-ce07-75c30c8343e8"
      },
      "source": [
        "print(tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iIwkdNa8vr4",
        "outputId": "ac57a1e5-048f-468b-a748-8e4c3f87b594"
      },
      "source": [
        "print(tfidf_vectorizer.idf_)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFYZ_JQ78vr4",
        "outputId": "434db531-c2e5-42f3-9bed-dd04bae1c81b"
      },
      "source": [
        "tfidf_output.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRCIDNX8vr5",
        "outputId": "dfc4d872-cd28-4d3a-c3ab-55c1d843a67d"
      },
      "source": [
        "skl_output = tfidf_vectorizer.transform(corpus)\n",
        "print(skl_output)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (3, 8)\t0.38408524091481483\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTI7scDM8vr5",
        "outputId": "b4c5efeb-22ba-45ee-988d-724b3940733f"
      },
      "source": [
        "print(skl_output[3])"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZu7jrYl8vr5",
        "outputId": "65888967-d85c-46fe-f92d-05bb9ac7ffe2"
      },
      "source": [
        "print(skl_output[0].toarray())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAoUzxH58vr5"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "import collections"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYEJFWzH8vr5"
      },
      "source": [
        "def get_unique_words(data):\n",
        "  unique_words = set()\n",
        "\n",
        "  if isinstance(data, (list,)):\n",
        "    for row in data:\n",
        "      for word in row.split(' '):\n",
        "        if(len(word) < 2):\n",
        "          continue\n",
        "        unique_words.add(word)\n",
        "    \n",
        "    unique_words = sorted(list(unique_words))\n",
        "    return unique_words\n",
        "  else:\n",
        "    print('pass list of sentences')\n",
        "\n",
        "\n",
        "def get_vocab(unique_words):\n",
        "  vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "  return vocab\n",
        "\n",
        "\n",
        "def transform(corpus, vocab):\n",
        "  rows = []\n",
        "  columns = []\n",
        "  values = []\n",
        "\n",
        "  if isinstance(corpus, (list,)):\n",
        "    for index, row in enumerate(tqdm(corpus)):\n",
        "      word_freq = dict(Counter(row.split()))\n",
        "      for word, freq in word_freq.items():\n",
        "        if len(word) < 2:\n",
        "          continue\n",
        "        \n",
        "        col_index = vocab.get(word, -1)\n",
        "        if col_index != -1:\n",
        "          rows.append(index)\n",
        "          columns.append(col_index)\n",
        "          values.append(freq)\n",
        "    return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(vocab)))\n",
        "  else:\n",
        "    print('pass a list of strings')\n",
        "\n",
        "\n",
        "def get_freq(corpus, unique_words):\n",
        "  flattened = [val for sublist in corpus for val in sublist.split(' ')]\n",
        "  for word in unique_words:\n",
        "    freq[word] = flattened.count(word)\n",
        "  return freq\n",
        "\n",
        "\n",
        "def find_in_str(str, word):\n",
        "  str_list = str.split(' ')\n",
        "  for i in range(len(str_list)):\n",
        "    if(word == str_list[i]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def compute_tfidf(corpus, unique_words, transform_output):\n",
        "  idfDict = {}\n",
        "  rows = []\n",
        "  columns = []\n",
        "  tf = []\n",
        "  idf = []\n",
        "  values = []\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    count = 0\n",
        "    \n",
        "    for j in range(len(unique_words)):\n",
        "      if(transform_output[i][j] > 0):\n",
        "        count += transform_output[i][j]\n",
        "    for j in range(len(unique_words)):\n",
        "      tf_value = transform_output[i][j] / count\n",
        "      idf_value = math.log( (len(corpus) + 1)/( float(get_idf(corpus, unique_words[j] ) + 1)) ) + 1\n",
        "      # print(\"tf\", i, j, tf_value, idf_value)\n",
        "      rows.append(i)\n",
        "      columns.append(j)\n",
        "      values.append(tf_value * idf_value)\n",
        "  return csr_matrix((values, (rows, columns)), shape = (len(corpus), len(unique_words)))\n",
        "\n",
        "\n",
        "def get_idf(corpus, word):\n",
        "  count = 0\n",
        "  for j in range(len(corpus)):\n",
        "    if(find_in_str(corpus[j], word)):\n",
        "      count += 1\n",
        "  return count\n"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9MpEh1u_i-G",
        "outputId": "bb0a4ced-43bf-49ff-daaa-35ee20810f79"
      },
      "source": [
        "unique_words = get_unique_words(corpus)\n",
        "vocab = get_vocab(unique_words)\n",
        "frequency_of_words = get_freq(corpus, unique_words)\n",
        "sparse_matrix = transform(corpus, vocab)\n",
        "transform_output = transform(corpus, vocab).toarray()\n",
        "print(\"\\n\")\n",
        "# print(unique_words)\n",
        "# print(vocab)\n",
        "# print(frequency_of_words)\n",
        "# print(sparse_matrix)\n",
        "# print(transform_output)\n",
        "tf_idf = compute_tfidf(corpus, unique_words, transform_output)\n",
        "print(round( normalize(tf_idf, norm = 'l2'), 6) )"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 8285.04it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 11514.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  (0, 0)\t0.0\n",
            "  (0, 1)\t0.469791\n",
            "  (0, 2)\t0.580286\n",
            "  (0, 3)\t0.384085\n",
            "  (0, 4)\t0.0\n",
            "  (0, 5)\t0.0\n",
            "  (0, 6)\t0.384085\n",
            "  (0, 7)\t0.0\n",
            "  (0, 8)\t0.384085\n",
            "  (1, 0)\t0.0\n",
            "  (1, 1)\t0.687624\n",
            "  (1, 2)\t0.0\n",
            "  (1, 3)\t0.281089\n",
            "  (1, 4)\t0.0\n",
            "  (1, 5)\t0.538648\n",
            "  (1, 6)\t0.281089\n",
            "  (1, 7)\t0.0\n",
            "  (1, 8)\t0.281089\n",
            "  (2, 0)\t0.511849\n",
            "  (2, 1)\t0.0\n",
            "  (2, 2)\t0.0\n",
            "  (2, 3)\t0.267104\n",
            "  (2, 4)\t0.511849\n",
            "  (2, 5)\t0.0\n",
            "  (2, 6)\t0.267104\n",
            "  (2, 7)\t0.511849\n",
            "  (2, 8)\t0.267104\n",
            "  (3, 0)\t0.0\n",
            "  (3, 1)\t0.469791\n",
            "  (3, 2)\t0.580286\n",
            "  (3, 3)\t0.384085\n",
            "  (3, 4)\t0.0\n",
            "  (3, 5)\t0.0\n",
            "  (3, 6)\t0.384085\n",
            "  (3, 7)\t0.0\n",
            "  (3, 8)\t0.384085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhn25nFnclz6",
        "outputId": "c6602ce7-53cc-42aa-bbd4-59ef9afb8ae1"
      },
      "source": [
        "tfidf_output = document_matrix(corpus, tfidf_vectorizer)\n",
        "print(tfidf_output)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        and  document     first  ...       the     third      this\n",
            "0  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "1  0.000000  0.687624  0.000000  ...  0.281089  0.000000  0.281089\n",
            "2  0.511849  0.000000  0.000000  ...  0.267104  0.511849  0.267104\n",
            "3  0.000000  0.469791  0.580286  ...  0.384085  0.000000  0.384085\n",
            "\n",
            "[4 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfpBFMTIFW1K"
      },
      "source": [
        "## Observation:\n",
        "*   The list of unique words and their frequencies in entire document is same as the one calculated using TfidfVectorizer\n",
        "*   The transform matrix that contains unique words is same as get_feature_names of scikit learn TfidfVectorizer\n",
        "*   The transform output matrix is same as count_output that we calculated previously using scikit learn CountVectorizer.\n",
        "*   Shape of the transform matrix matches with the one calculated using TfidfVectorizer transform method.\n",
        "*   IDF values of all unique words from the entire document matches the values that were counted using scikit learn TfidfVectorizer.\n",
        "*   IDF_ values calculated by multiplying TF*IDF values individually, matches with the values calculated using TfidfVectorizer._idf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI9PsvSccOX5"
      },
      "source": [
        "# Tast-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "-sUDiXcFcQcb",
        "outputId": "0421df9d-bbd0-4f93-bedf-7f70903b2af4"
      },
      "source": [
        "import pickle\n",
        "with open('cleaned strings', 'rb') as f:\n",
        "  corpus = pickle.load(f)\n",
        "\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-234-fc29e6babee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleaned strings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of documents in corpus = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleaned strings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BFBJ6yvdBVI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}